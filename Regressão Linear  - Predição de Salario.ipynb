{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Regressão Linear Simples usando o TensorFlow - Predição de Salário em Função dos anos de experiência</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Neste Notebook veremos um exemplo simples de regressão linear, usando as bibliotecas tensorflow, sklearn,pandas e matplotlib.</p>\n",
    "    <p>Para o tensorflow usaremos o high level api(estimators), pois o nivel de abstração é maior e consequentemente perderemos menos tempo para treinar o nosso modelo.</p> \n",
    "   <p>A base de dados utilizada foi fornecida pelo site Kaggle, onde o link encontra-se a seguir:</p>\n",
    "<p> <a href =\"https://www.kaggle.com/karthickveerakumar/salary-data-simple-linear-regression\">Clique Aqui para ser direcionado a base de dados do Kaggle</a></p>\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Introdução</h3>\n",
    "\n",
    "<p>Para este problema devemos ser capazes de predizer a remuneração de uma pessoa a partir de uma base de dados previamente conhecida, contendo anos de experiência de determinados funcionários em uma empresa e seus respectivos salários.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Importando os Módulos necessários</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Para iniciarmos devemos importar os módulos.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy  as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing   import StandardScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Importando os Dados</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Usaremos a biblioteca pandas para criarmos um dataframe e assim podermos importar os dados.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = pd.read_csv(\"/home/gabriel/Downloads/Salary_Data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Antes de prosseguirmos, vamos confirmar que nosso arquivo base está importado corretamente para isso veremos \n",
    "o seu tipo, seu shape e seus 5 primeiros dados :</h>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YearsExperience</th>\n",
       "      <th>Salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.1</td>\n",
       "      <td>39343.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.3</td>\n",
       "      <td>46205.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.5</td>\n",
       "      <td>37731.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>43525.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.2</td>\n",
       "      <td>39891.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   YearsExperience   Salary\n",
       "0              1.1  39343.0\n",
       "1              1.3  46205.0\n",
       "2              1.5  37731.0\n",
       "3              2.0  43525.0\n",
       "4              2.2  39891.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Uma vez importado corretamente a nossa base devemos criar dois tipos de dataframes, separando assim as variáveis dependentes das variáveis independentes.</p>\n",
    "<p>Para isso usaremos o método iloc para realizarmos a indexação... Lembrando que esta indexação em python é realizada inicialmente do numero 0 (zero).</p>\n",
    "<p>Devemos ainda lembrar que o nosso principal objetivo é trabalharmos numericamente com esses valores, realizando assim calculos matemáticos e para isso devemos transformar nosso dataframe em um array numpy.</p>\n",
    "<p>Para tal usaremos o método values</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    " x = base.iloc[:,0:1].values\n",
    " y = base.iloc[:,1:2].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Conferiremos assim o tipo e o shape dos arrays criados: </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Visualizando os Dados</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>É de suma importancia que antes de iniciarmos o nosso modelo preditivo tenhamos a certeza que a regressão linear é um bom metodo para a resolução do problema e para isso plotaremos um grafico relacionando as duas variáveis.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f0612db9ef0>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(x,y,\"o\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Escalonando os Dados</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Como os dados possuem escalas diferente, precisamos escalona-los e para isso utilizaremos o módulo sklearn.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_scaler = StandardScaler().fit(x)\n",
    "y_scaler = StandardScaler().fit(y)\n",
    "x = x_scaler.transform(x)\n",
    "y = y_scaler.transform(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Visto que o escalonamento ja foi realizado plotaremos novamente as variaveis para termos a certeza que a relação linear não foi perdida.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f0612d44d68>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(x,y,\"o\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Criando conjunto de Treino e Conjunto de Testes</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Depois de ja realizado o escalonamento, precisamos então subdividirmos os nossos dados em <b> conjunto de treino</b> e em <b> conjunto de testes</b>, para que assim possamos treinar e avaliar o nosso algoritmo.</p>\n",
    "<p>Usaremos mais uma vez o modulo sklearn para realizarmos tal ação.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size  =0.333,shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Visto que configuramos o conjunto de teste como sendo 33% do conjunto de dados, esperamos então os arrays de teste com tamanho de 10 unidades e os arrays de treino com 20 unidades. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 1)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 1)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 1)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <h3>Criando o modelo de regressão</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Aqui criaremos um placeholder para armazenar a variavel x.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "colum_x = [tf.feature_column.numeric_column(\"x\",shape=[1])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Instanciaremos então um regressor linear, onde daremos a ele o placeholder criado acima.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpovwbx4lw\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmpovwbx4lw', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f0612d06550>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "regressor = tf.estimator.LinearRegressor(feature_columns=colum_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Treinando o modelo </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Vamos agora definir o conjunto de treinamento no tensorflow e junto dessa definição colocaremos alguns parametros importantes para que o treinamento seja realizado com sucesso, são eles :</p>\n",
    "<p>Batch_size: Tamanho do lote de cada lote </p>\n",
    "<p>num_epochs: Numero de rodadas pelo conjunto de treino completo</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "conjunto_treinamento = tf.estimator.inputs.numpy_input_fn({\"x\":x_train},y_train,batch_size = 2,\n",
    "                                                           num_epochs = None,shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Visto que tudo está pronto, basta então realizarmos o treinamento: </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/gabriel/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "WARNING:tensorflow:From /home/gabriel/anaconda3/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/inputs/queues/feeding_queue_runner.py:62: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From /home/gabriel/anaconda3/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/inputs/queues/feeding_functions.py:500: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:From /home/gabriel/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/feature_column/feature_column_v2.py:305: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.add_weight` method instead.\n",
      "WARNING:tensorflow:From /home/gabriel/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From /home/gabriel/anaconda3/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/canned/linear.py:308: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "WARNING:tensorflow:From /home/gabriel/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/array_ops.py:1475: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "WARNING:tensorflow:From /home/gabriel/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/training/monitored_session.py:882: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmpovwbx4lw/model.ckpt.\n",
      "INFO:tensorflow:loss = 2.7972221, step = 1\n",
      "INFO:tensorflow:global_step/sec: 398.22\n",
      "INFO:tensorflow:loss = 0.0986863, step = 101 (0.257 sec)\n",
      "INFO:tensorflow:global_step/sec: 518.067\n",
      "INFO:tensorflow:loss = 0.1520992, step = 201 (0.190 sec)\n",
      "INFO:tensorflow:global_step/sec: 552.242\n",
      "INFO:tensorflow:loss = 0.06640876, step = 301 (0.197 sec)\n",
      "INFO:tensorflow:global_step/sec: 536.045\n",
      "INFO:tensorflow:loss = 0.116385475, step = 401 (0.171 sec)\n",
      "INFO:tensorflow:global_step/sec: 564.918\n",
      "INFO:tensorflow:loss = 0.011319951, step = 501 (0.174 sec)\n",
      "INFO:tensorflow:global_step/sec: 607.836\n",
      "INFO:tensorflow:loss = 0.012843827, step = 601 (0.164 sec)\n",
      "INFO:tensorflow:global_step/sec: 660.826\n",
      "INFO:tensorflow:loss = 0.005475636, step = 701 (0.151 sec)\n",
      "INFO:tensorflow:global_step/sec: 668.751\n",
      "INFO:tensorflow:loss = 0.09371278, step = 801 (0.150 sec)\n",
      "INFO:tensorflow:global_step/sec: 626.549\n",
      "INFO:tensorflow:loss = 0.02030995, step = 901 (0.160 sec)\n",
      "INFO:tensorflow:global_step/sec: 680.794\n",
      "INFO:tensorflow:loss = 0.00041510968, step = 1001 (0.147 sec)\n",
      "INFO:tensorflow:global_step/sec: 626.277\n",
      "INFO:tensorflow:loss = 0.004933095, step = 1101 (0.160 sec)\n",
      "INFO:tensorflow:global_step/sec: 599.093\n",
      "INFO:tensorflow:loss = 0.07750542, step = 1201 (0.167 sec)\n",
      "INFO:tensorflow:global_step/sec: 617.13\n",
      "INFO:tensorflow:loss = 0.059298072, step = 1301 (0.162 sec)\n",
      "INFO:tensorflow:global_step/sec: 586.939\n",
      "INFO:tensorflow:loss = 0.02134172, step = 1401 (0.171 sec)\n",
      "INFO:tensorflow:global_step/sec: 648.179\n",
      "INFO:tensorflow:loss = 0.16414884, step = 1501 (0.154 sec)\n",
      "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 1514 vs previous value: 1514. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
      "INFO:tensorflow:global_step/sec: 487.071\n",
      "INFO:tensorflow:loss = 0.061134465, step = 1601 (0.205 sec)\n",
      "INFO:tensorflow:global_step/sec: 662.108\n",
      "INFO:tensorflow:loss = 0.06760563, step = 1701 (0.151 sec)\n",
      "INFO:tensorflow:global_step/sec: 637.109\n",
      "INFO:tensorflow:loss = 0.006594713, step = 1801 (0.157 sec)\n",
      "INFO:tensorflow:global_step/sec: 669.721\n",
      "INFO:tensorflow:loss = 0.06143674, step = 1901 (0.150 sec)\n",
      "INFO:tensorflow:global_step/sec: 601.694\n",
      "INFO:tensorflow:loss = 0.057290025, step = 2001 (0.166 sec)\n",
      "INFO:tensorflow:global_step/sec: 676.751\n",
      "INFO:tensorflow:loss = 0.023498677, step = 2101 (0.147 sec)\n",
      "INFO:tensorflow:global_step/sec: 649.128\n",
      "INFO:tensorflow:loss = 0.16981113, step = 2201 (0.154 sec)\n",
      "INFO:tensorflow:global_step/sec: 563.947\n",
      "INFO:tensorflow:loss = 0.025607023, step = 2301 (0.177 sec)\n",
      "INFO:tensorflow:global_step/sec: 667.81\n",
      "INFO:tensorflow:loss = 0.09323449, step = 2401 (0.150 sec)\n",
      "INFO:tensorflow:global_step/sec: 571.349\n",
      "INFO:tensorflow:loss = 0.03442462, step = 2501 (0.176 sec)\n",
      "INFO:tensorflow:global_step/sec: 482.67\n",
      "INFO:tensorflow:loss = 0.12037691, step = 2601 (0.207 sec)\n",
      "INFO:tensorflow:global_step/sec: 493.585\n",
      "INFO:tensorflow:loss = 0.004785612, step = 2701 (0.203 sec)\n",
      "INFO:tensorflow:global_step/sec: 456.727\n",
      "INFO:tensorflow:loss = 0.08126071, step = 2801 (0.218 sec)\n",
      "INFO:tensorflow:global_step/sec: 602.787\n",
      "INFO:tensorflow:loss = 0.027169801, step = 2901 (0.166 sec)\n",
      "INFO:tensorflow:global_step/sec: 618.704\n",
      "INFO:tensorflow:loss = 0.01286639, step = 3001 (0.161 sec)\n",
      "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 3024 vs previous value: 3024. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
      "INFO:tensorflow:global_step/sec: 588.04\n",
      "INFO:tensorflow:loss = 0.093661495, step = 3101 (0.170 sec)\n",
      "INFO:tensorflow:global_step/sec: 586.163\n",
      "INFO:tensorflow:loss = 0.07396346, step = 3201 (0.171 sec)\n",
      "INFO:tensorflow:global_step/sec: 620.797\n",
      "INFO:tensorflow:loss = 0.0017699911, step = 3301 (0.161 sec)\n",
      "INFO:tensorflow:global_step/sec: 614.492\n",
      "INFO:tensorflow:loss = 0.16811419, step = 3401 (0.163 sec)\n",
      "INFO:tensorflow:global_step/sec: 710.428\n",
      "INFO:tensorflow:loss = 0.13991043, step = 3501 (0.141 sec)\n",
      "INFO:tensorflow:global_step/sec: 656.639\n",
      "INFO:tensorflow:loss = 0.1635161, step = 3601 (0.152 sec)\n",
      "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 3653 vs previous value: 3653. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
      "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 3683 vs previous value: 3683. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
      "INFO:tensorflow:global_step/sec: 362.655\n",
      "INFO:tensorflow:loss = 0.08735729, step = 3701 (0.279 sec)\n",
      "INFO:tensorflow:global_step/sec: 364.293\n",
      "INFO:tensorflow:loss = 0.09742917, step = 3801 (0.271 sec)\n",
      "INFO:tensorflow:global_step/sec: 724.876\n",
      "INFO:tensorflow:loss = 0.10667604, step = 3901 (0.138 sec)\n",
      "INFO:tensorflow:global_step/sec: 603.042\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.08457695, step = 4001 (0.166 sec)\n",
      "INFO:tensorflow:global_step/sec: 702.5\n",
      "INFO:tensorflow:loss = 0.09029116, step = 4101 (0.142 sec)\n",
      "INFO:tensorflow:global_step/sec: 628.306\n",
      "INFO:tensorflow:loss = 0.17089608, step = 4201 (0.159 sec)\n",
      "INFO:tensorflow:global_step/sec: 690.681\n",
      "INFO:tensorflow:loss = 0.07471736, step = 4301 (0.145 sec)\n",
      "INFO:tensorflow:global_step/sec: 692.095\n",
      "INFO:tensorflow:loss = 0.00026261157, step = 4401 (0.145 sec)\n",
      "INFO:tensorflow:global_step/sec: 720.51\n",
      "INFO:tensorflow:loss = 0.07157182, step = 4501 (0.139 sec)\n",
      "INFO:tensorflow:global_step/sec: 765.066\n",
      "INFO:tensorflow:loss = 0.02099699, step = 4601 (0.131 sec)\n",
      "INFO:tensorflow:global_step/sec: 691.981\n",
      "INFO:tensorflow:loss = 0.08763631, step = 4701 (0.145 sec)\n",
      "INFO:tensorflow:global_step/sec: 716.124\n",
      "INFO:tensorflow:loss = 0.01688317, step = 4801 (0.140 sec)\n",
      "INFO:tensorflow:global_step/sec: 722.088\n",
      "INFO:tensorflow:loss = 0.009110118, step = 4901 (0.139 sec)\n",
      "INFO:tensorflow:global_step/sec: 711.188\n",
      "INFO:tensorflow:loss = 0.046339802, step = 5001 (0.141 sec)\n",
      "INFO:tensorflow:global_step/sec: 700.511\n",
      "INFO:tensorflow:loss = 0.0054595456, step = 5101 (0.142 sec)\n",
      "INFO:tensorflow:global_step/sec: 666.738\n",
      "INFO:tensorflow:loss = 0.08970054, step = 5201 (0.150 sec)\n",
      "INFO:tensorflow:global_step/sec: 732.324\n",
      "INFO:tensorflow:loss = 0.06113256, step = 5301 (0.139 sec)\n",
      "INFO:tensorflow:global_step/sec: 648.34\n",
      "INFO:tensorflow:loss = 0.009877367, step = 5401 (0.152 sec)\n",
      "INFO:tensorflow:global_step/sec: 672.093\n",
      "INFO:tensorflow:loss = 0.12134601, step = 5501 (0.149 sec)\n",
      "INFO:tensorflow:global_step/sec: 696.647\n",
      "INFO:tensorflow:loss = 0.09853068, step = 5601 (0.144 sec)\n",
      "INFO:tensorflow:global_step/sec: 679.874\n",
      "INFO:tensorflow:loss = 0.034533247, step = 5701 (0.147 sec)\n",
      "INFO:tensorflow:global_step/sec: 655.827\n",
      "INFO:tensorflow:loss = 0.04098077, step = 5801 (0.153 sec)\n",
      "INFO:tensorflow:global_step/sec: 651.272\n",
      "INFO:tensorflow:loss = 0.08151432, step = 5901 (0.154 sec)\n",
      "INFO:tensorflow:global_step/sec: 739.157\n",
      "INFO:tensorflow:loss = 0.016351335, step = 6001 (0.135 sec)\n",
      "INFO:tensorflow:global_step/sec: 655.298\n",
      "INFO:tensorflow:loss = 0.051717114, step = 6101 (0.153 sec)\n",
      "INFO:tensorflow:global_step/sec: 672.785\n",
      "INFO:tensorflow:loss = 0.098073475, step = 6201 (0.149 sec)\n",
      "INFO:tensorflow:global_step/sec: 667.527\n",
      "INFO:tensorflow:loss = 0.12435646, step = 6301 (0.150 sec)\n",
      "INFO:tensorflow:global_step/sec: 638.891\n",
      "INFO:tensorflow:loss = 0.091461495, step = 6401 (0.156 sec)\n",
      "INFO:tensorflow:global_step/sec: 666.978\n",
      "INFO:tensorflow:loss = 0.005961065, step = 6501 (0.150 sec)\n",
      "INFO:tensorflow:global_step/sec: 703.604\n",
      "INFO:tensorflow:loss = 0.03231131, step = 6601 (0.142 sec)\n",
      "INFO:tensorflow:global_step/sec: 678.101\n",
      "INFO:tensorflow:loss = 0.009211819, step = 6701 (0.147 sec)\n",
      "INFO:tensorflow:global_step/sec: 657.656\n",
      "INFO:tensorflow:loss = 0.0926758, step = 6801 (0.153 sec)\n",
      "INFO:tensorflow:global_step/sec: 672.207\n",
      "INFO:tensorflow:loss = 0.07686684, step = 6901 (0.148 sec)\n",
      "INFO:tensorflow:global_step/sec: 630.605\n",
      "INFO:tensorflow:loss = 0.030085953, step = 7001 (0.159 sec)\n",
      "INFO:tensorflow:global_step/sec: 614.775\n",
      "INFO:tensorflow:loss = 0.12087758, step = 7101 (0.162 sec)\n",
      "INFO:tensorflow:global_step/sec: 656.779\n",
      "INFO:tensorflow:loss = 0.09581978, step = 7201 (0.152 sec)\n",
      "INFO:tensorflow:global_step/sec: 651.609\n",
      "INFO:tensorflow:loss = 0.03338723, step = 7301 (0.154 sec)\n",
      "INFO:tensorflow:global_step/sec: 649.041\n",
      "INFO:tensorflow:loss = 0.082437776, step = 7401 (0.156 sec)\n",
      "INFO:tensorflow:global_step/sec: 684.244\n",
      "INFO:tensorflow:loss = 0.12531297, step = 7501 (0.144 sec)\n",
      "INFO:tensorflow:global_step/sec: 638.293\n",
      "INFO:tensorflow:loss = 0.009993765, step = 7601 (0.156 sec)\n",
      "INFO:tensorflow:global_step/sec: 602.917\n",
      "INFO:tensorflow:loss = 0.041194737, step = 7701 (0.166 sec)\n",
      "INFO:tensorflow:global_step/sec: 640.642\n",
      "INFO:tensorflow:loss = 0.017612588, step = 7801 (0.156 sec)\n",
      "INFO:tensorflow:global_step/sec: 676.217\n",
      "INFO:tensorflow:loss = 0.06969894, step = 7901 (0.148 sec)\n",
      "INFO:tensorflow:global_step/sec: 653.299\n",
      "INFO:tensorflow:loss = 0.015891671, step = 8001 (0.153 sec)\n",
      "INFO:tensorflow:global_step/sec: 650.415\n",
      "INFO:tensorflow:loss = 0.05802507, step = 8101 (0.154 sec)\n",
      "INFO:tensorflow:global_step/sec: 681.231\n",
      "INFO:tensorflow:loss = 0.109642446, step = 8201 (0.146 sec)\n",
      "INFO:tensorflow:global_step/sec: 669.077\n",
      "INFO:tensorflow:loss = 0.12680437, step = 8301 (0.150 sec)\n",
      "INFO:tensorflow:global_step/sec: 672.219\n",
      "INFO:tensorflow:loss = 0.08464317, step = 8401 (0.150 sec)\n",
      "INFO:tensorflow:global_step/sec: 631.28\n",
      "INFO:tensorflow:loss = 0.0038480915, step = 8501 (0.157 sec)\n",
      "INFO:tensorflow:global_step/sec: 651.135\n",
      "INFO:tensorflow:loss = 0.07300353, step = 8601 (0.153 sec)\n",
      "INFO:tensorflow:global_step/sec: 697.023\n",
      "INFO:tensorflow:loss = 0.119547404, step = 8701 (0.143 sec)\n",
      "INFO:tensorflow:global_step/sec: 671.583\n",
      "INFO:tensorflow:loss = 0.15932396, step = 8801 (0.149 sec)\n",
      "INFO:tensorflow:global_step/sec: 676.088\n",
      "INFO:tensorflow:loss = 0.09688617, step = 8901 (0.148 sec)\n",
      "INFO:tensorflow:global_step/sec: 618.988\n",
      "INFO:tensorflow:loss = 0.031909805, step = 9001 (0.161 sec)\n",
      "INFO:tensorflow:global_step/sec: 701.883\n",
      "INFO:tensorflow:loss = 0.067755595, step = 9101 (0.142 sec)\n",
      "INFO:tensorflow:global_step/sec: 633.617\n",
      "INFO:tensorflow:loss = 0.14743826, step = 9201 (0.158 sec)\n",
      "INFO:tensorflow:global_step/sec: 655.38\n",
      "INFO:tensorflow:loss = 0.0014859294, step = 9301 (0.152 sec)\n",
      "INFO:tensorflow:global_step/sec: 700.841\n",
      "INFO:tensorflow:loss = 0.10435177, step = 9401 (0.143 sec)\n",
      "INFO:tensorflow:global_step/sec: 631.244\n",
      "INFO:tensorflow:loss = 0.06555259, step = 9501 (0.159 sec)\n",
      "INFO:tensorflow:global_step/sec: 608.784\n",
      "INFO:tensorflow:loss = 0.09678283, step = 9601 (0.164 sec)\n",
      "INFO:tensorflow:global_step/sec: 660.85\n",
      "INFO:tensorflow:loss = 0.11006379, step = 9701 (0.151 sec)\n",
      "INFO:tensorflow:global_step/sec: 641.343\n",
      "INFO:tensorflow:loss = 0.009016293, step = 9801 (0.156 sec)\n",
      "INFO:tensorflow:global_step/sec: 658.475\n",
      "INFO:tensorflow:loss = 0.016105242, step = 9901 (0.152 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 10000 into /tmp/tmpovwbx4lw/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.01103786.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow_estimator.python.estimator.canned.linear.LinearRegressor at 0x7f0612c8f748>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor.train(conjunto_treinamento,steps = 10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Para termos uma ideia de como o nosso modelo se comportou, vamos salvar em uma variável suas métricas: <p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-01-26T14:14:41Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpovwbx4lw/model.ckpt-10000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [1000/10000]\n",
      "INFO:tensorflow:Evaluation [2000/10000]\n",
      "INFO:tensorflow:Evaluation [3000/10000]\n",
      "INFO:tensorflow:Evaluation [4000/10000]\n",
      "INFO:tensorflow:Evaluation [5000/10000]\n",
      "INFO:tensorflow:Evaluation [6000/10000]\n",
      "INFO:tensorflow:Evaluation [7000/10000]\n",
      "INFO:tensorflow:Evaluation [8000/10000]\n",
      "INFO:tensorflow:Evaluation [9000/10000]\n",
      "INFO:tensorflow:Evaluation [10000/10000]\n",
      "INFO:tensorflow:Finished evaluation at 2020-01-26-14:14:53\n",
      "INFO:tensorflow:Saving dict for global step 10000: average_loss = 0.035439037, global_step = 10000, label/mean = -0.057095386, loss = 0.07087807, prediction/mean = -0.05086288\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 10000: /tmp/tmpovwbx4lw/model.ckpt-10000\n"
     ]
    }
   ],
   "source": [
    "metricas_treino = regressor.evaluate(conjunto_treinamento,steps =10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Testando o Modelo</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Criaremos o conjunto de Teste, definindo os parâmetros da mesma forma que anteriormente. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "conjunto_teste = tf.estimator.inputs.numpy_input_fn({\"x\":x_test},y_test,batch_size = 2,\n",
    "                                                           num_epochs = 1000,shuffle = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Para termos uma ideia de como o nosso modelo se comportou diante do conjunto de teste, vamos salvar em uma variável suas métricas: <p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-01-26T14:15:05Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpovwbx4lw/model.ckpt-10000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [100/1000]\n",
      "INFO:tensorflow:Evaluation [200/1000]\n",
      "INFO:tensorflow:Evaluation [300/1000]\n",
      "INFO:tensorflow:Evaluation [400/1000]\n",
      "INFO:tensorflow:Evaluation [500/1000]\n",
      "INFO:tensorflow:Evaluation [600/1000]\n",
      "INFO:tensorflow:Evaluation [700/1000]\n",
      "INFO:tensorflow:Evaluation [800/1000]\n",
      "INFO:tensorflow:Evaluation [900/1000]\n",
      "INFO:tensorflow:Evaluation [1000/1000]\n",
      "INFO:tensorflow:Finished evaluation at 2020-01-26-14:15:07\n",
      "INFO:tensorflow:Saving dict for global step 10000: average_loss = 0.06160666, global_step = 10000, label/mean = 0.112793826, loss = 0.12321332, prediction/mean = 0.16869582\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 10000: /tmp/tmpovwbx4lw/model.ckpt-10000\n"
     ]
    }
   ],
   "source": [
    "metricas_teste = regressor.evaluate(conjunto_teste,steps = 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Avaliando o Modelo </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'average_loss': 0.06160666,\n",
       " 'label/mean': 0.112793826,\n",
       " 'loss': 0.12321332,\n",
       " 'prediction/mean': 0.16869582,\n",
       " 'global_step': 10000}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metricas_teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'average_loss': 0.035439037,\n",
       " 'label/mean': -0.057095386,\n",
       " 'loss': 0.07087807,\n",
       " 'prediction/mean': -0.05086288,\n",
       " 'global_step': 10000}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metricas_treino"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Avaliando o nosso modelo podemos ver que : </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O Conjunto de Treino teve um desempenho melhor que o conjunto de teste, com um erro de: 0.07087807\n"
     ]
    }
   ],
   "source": [
    "if metricas_treino[\"loss\"] > metricas_teste[\"loss\"]:\n",
    "    print(\"O Conjunto de Teste teve um desempenho melhor que o conjunto de treino, com um erro de:\", \n",
    "          metricas_teste[\"loss\"])\n",
    "else:\n",
    "    print(\"O Conjunto de Treino teve um desempenho melhor que o conjunto de teste, com um erro de:\", \n",
    "          metricas_treino[\"loss\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Realizando Predições</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Este é o momento de realizarmos predições, ou seja, entraremos com novos valores de experiência de cada colaborador e o modelo que treinamos nos retornará o salário ideal.</p>\n",
    "<p>Para isso criaremos um array com os seguintes anos de experiência:</p>\n",
    "<p>10 anos</p>\n",
    "<p>11 anos</p>\n",
    "<p>12 anos</p>\n",
    "<p>13 anos</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_x = np.array([[10.0],[11.0],[12.0],[13.0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Como foi visto outrora necessitamos escalonar esses dados:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_x = x_scaler.transform(predict_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Instanciaremos então o objeto que irá fazer as predições e alimentaremos o mesmo com o placeholder x, que por sua vez foi alimentado com o array que escalonamos no passo anterior.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_model =tf.estimator.inputs.numpy_input_fn({\"x\":predict_x},shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Para vermos os resultados da predição faremos um loop for e guardaremos em um array.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpovwbx4lw/model.ckpt-10000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    }
   ],
   "source": [
    "salarios=[]\n",
    "for i in regressor.predict(input_fn = predict_model):\n",
    "    salarios.append(i[\"predictions\"])\n",
    "\n",
    "salarios_np_normalizados= np.asarray(salarios).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Por fim faremos a operação inversa do escalonamento e obteremos as predições reais.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[119793.45],\n",
       "       [129005.53],\n",
       "       [138217.61],\n",
       "       [147429.69]], dtype=float32)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "salarios_np =y_scaler.inverse_transform(salarios_np_normalizados)\n",
    "salarios_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
